{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  #ou use df.info() to find all missing values and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() #you use df.describe() to understand the statistical distribution of your numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### filling missing values and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Embarked column (Port of Embarkation) has only 2 missing values \n",
    "(889 non-null counts). Since this is a very small number, \n",
    "we can fill them with the Mode (the most frequent value).\n",
    "'''\n",
    "\n",
    "df['Embarked'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why the Mode? Since it's a categorical feature, \n",
    "we can't use the average. The mode represents the most \n",
    "typical boarding location, which is the safest guess.\n",
    "'''\n",
    "\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "inplace=True is a parameter used in some methods to directly modify the original DataFrame or Series. When you use inplace=True, the method returns None, and the changes are made to the existing object. In contrast, the default behavior (inplace=False) returns a new DataFrame or Series with the changes, leaving the original object unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Age column is crucial for survival analysis \n",
    "but has ~177 missing values. Dropping that many rows \n",
    "would lose too much data, so we will use \n",
    "Imputation (filling in the blanks).\n",
    "\n",
    "\n",
    "Why the Median over the Mean? \n",
    "The median is less sensitive to outliers \n",
    "(like a single passenger who is 80) than the mean,\n",
    "making it a more robust central tendency measure \n",
    "for filling in missing data.\n",
    "\n",
    "'''\n",
    "\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabin has high count of missing values\n",
    "\n",
    "missing_cabin_percent = (df['Cabin'].isnull().sum()/df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing Cabin values: {missing_cabin_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "axis=1: Specifies that the operation should be performed on columns. If you were dropping a row, you would use axis=0 (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not useful because too many missing values and not useful\n",
    "\n",
    "df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()   # shows data is clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Phase 4: Univariate Analysis (Individual Variable Exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Task 9: Analyze the Target Variable (Survived)\n",
    "Our target is a categorical variable (0=No, 1=Yes).\n",
    "check Counts and Proportions: Use a count plot \n",
    "to visualize the ratio of survivors to non-survivors\n",
    "\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Survived', data=df)\n",
    "plt.title('Survival Count (0=No, 1=Yes)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task 10: Analyze Key Categorical Features (Sex, Pclass)\n",
    "These variables are strong predictors of survival.\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Sex', data=df)\n",
    "plt.title('Passenger Count by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Pclass', data=df)\n",
    "plt.title('Passenger Count by Class (1st, 2nd, 3rd)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "bins\n",
    "\n",
    "    What it does: bins divides the data into intervals, or \"buckets,\" for counting. The histplot then represents the frequency of data points in each interval with a bar.\n",
    "    How it works: When you set bins=30, you are telling the plot to divide the entire range of values in the 'Age' column into 30 equal-width bins.\n",
    "    Effect on the plot: The choice of the number of bins can significantly affect the histogram's appearance.\n",
    "        Too few bins might hide important details by over-generalizing the distribution.\n",
    "        Too many bins might produce a plot that is too jagged and influenced by random noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "kde\n",
    "\n",
    "    What it does: kde stands for Kernel Density Estimate. When kde=True, it overlays a smooth, continuous curve on top of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task 11: Analyze Key Numerical Features (Age, Fare)\n",
    "Numerical variables are best analyzed using distributions.\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['Age'], bins=30, kde=True)\n",
    "plt.title('Distribution of Passenger Ages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "skew:\n",
    "In statistics, a distribution is skewed when it is not symmetrical. In a symmetrical, or normal, distribution (a bell curve), data points are evenly distributed around the mean. Skewness measures the degree to which a distribution's shape deviates from this symmetrical bell curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "outlier -> An outlier is a data point that is significantly different from other observations in a dataset. It falls outside the overall pattern and can be either unusually high or unusually low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Fare'], bins=40, kde=True)\n",
    "plt.title('Distribution of Passenger Fares')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Phase 5: Bivariate Analysis (Finding Relationships)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task 12: Categorical Features vs. Survival\n",
    "Use Bar Plots to compare survival rates across categories.\n",
    "'''\n",
    "#Gender vs. Survival:\n",
    "\n",
    "sns.barplot(x='Sex', y='Survived', data=df, errorbar=None)\n",
    "plt.title('Survival Rate by Gender')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=df)\n",
    "plt.title('Survival Rate by Passenger Class')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x='Age', hue='Survived', fill=True, alpha=0.6)\n",
    "plt.title('Age Distribution by Survival Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Survived', y='Fare', data=df)\n",
    "plt.title('Fare Distribution by Survival Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Phase 6: Feature Engineering and Advanced EDA\n",
    "\n",
    "EDA doesn't just stop at existing columns; it involves creating new, more powerful features from the ones you have. This is called Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The columns SibSp (Siblings/Spouses) \n",
    "and Parch (Parents/Children) are related, \n",
    "but their combined size might be more predictive.\n",
    "Let's create a new feature called FamilySize.\n",
    "'''\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='FamilySize', y='Survived', data=df)\n",
    "plt.title('Survival Rate by Family Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    ".apply(lambda x: ...): This method applies a function to each value (x) in the 'Name' column. In this case, the function is a lambda function, which is a small, anonymous function defined right in the code.\n",
    "x.split(', ')[1]: This is the first part of the lambda function.\n",
    "\n",
    "    x is a single name string, like \"Braund, Mr. Owen Harris\".\n",
    "    split(', ') splits the string into a list of two parts, using , as the separator. For our example, the result is ['Braund', 'Mr. Owen Harris'].\n",
    "    [1] selects the second item from that list (remember, lists are zero-indexed), which is \"Mr. Owen Harris\".\n",
    "\n",
    ".split('.')[0]: This is the second part of the lambda function, chained to the first part.\n",
    "\n",
    "    .split('.') splits the string \"Mr. Owen Harris\" into a list, using the period . as the separator. The result is ['Mr', ' Owen Harris'].\n",
    "    [0] selects the first item from that new list, which is \"Mr\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task 15: Feature Engineering - Title Extraction ðŸ‘‘\n",
    "The Name column is text,\n",
    "but it holds valuable categorical \n",
    "information in the form of a \n",
    "passenger's title (e.g., 'Mr.', 'Miss.', 'Master.', 'Dr.'). \n",
    "Titles often correlate with social status, age, and gender, \n",
    "making them powerful predictors.\n",
    "'''\n",
    "\n",
    "df['Title'] = df['Name'].apply(lambda x: x.split(', ')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all titles with count < 10 and replace them with 'Rare'\n",
    "rare_titles = df['Title'].value_counts()[df['Title'].value_counts() < 10].index\n",
    "df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# Group the main titles (Miss/Mme/Ms and Lady/Countess/Dona are often grouped)\n",
    "df['Title'] = df['Title'].replace(['Ms', 'Mme', 'Mlle'], 'Miss')\n",
    "df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Dona'], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Title', y='Survived', data=df)\n",
    "plt.title('Survival Rate by Passenger Title')\n",
    "plt.xticks(rotation=45) # Rotate labels for readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### âš™ï¸ Phase 7: Preparation for Modeling\n",
    "\n",
    "Before we can train a model, we need to convert all the useful non-numerical data into numbers, a process called Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we won't use for a simple model\n",
    "df_model = df.drop(['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Why? SibSp and Parch were combined into FamilySize. Name, Ticket, and PassengerId are unique identifiers that don't help predict survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Convert Categorical Data using Dummy Variables: Machine learning models only understand numbers. We need to convert categorical text features (Sex, Embarked, Title) into numerical columns using One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Sex', 'Embarked', and 'Title' into numerical dummy variables\n",
    "df_model = pd.get_dummies(df_model, columns=['Sex', 'Embarked', 'Title'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### ðŸ§  Phase 8: Model Training (Logistic Regression)\n",
    "\n",
    "We will use Logistic Regression, the simplest and most interpretable model, perfect for a binary classification problem (predicting 0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# X is all features, y is the target variable\n",
    "X = df_model.drop('Survived', axis=1)\n",
    "y = df_model['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Split into Training and Test Sets: We train the model on 80% of the data and test its performance on the remaining 20% that it has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### âœ… Phase 9: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
